# Assessment of Deep Convolutional Neural Network Models for Species Identification of Forensically-Important Fly Maggots Based on Images of Posterior Spiracles
## Abstract
Forensic entomology is the branch of forensic science that is related to using arthropod specimens found in legal issues. Fly maggots are one of crucial pieces of evidence that can be used for estimating post-mortem intervals worldwide. However, the species-level identification of fly maggots is difficult, time consuming, and requires specialized taxonomic training. In this work, a novel method for the identification of different forensically-important fly species is proposed using convolutional neural networks (CNNs). The data used for the experiment were obtained from a digital camera connected to a compound microscope. We compared the performance of four widely used models that vary in complexity of architecture to evaluate tradeoffs in accuracy and speed for species classification including ResNet-101, Densenet161, Vgg19_bn, and AlexNet. In the validation step, all of the studied models provided 100% accuracy for identifying maggots of 4 species including *Chrysomya megacephala* (Diptera: Calliphoridae), *Chrysomya* (*Achoetandrus*) rufifacies (Diptera: Calliphoridae), *Lucilia cuprina* (Diptera: Calliphoridae), and *Musca domestica* (Diptera: Muscidae) based on images of posterior spiracles. However, AlexNet showed the fastest speed to process the identification model and presented a good balance between performance and speed. Therefore, the AlexNet model was selected for the testing step. The results of the confusion matrix of AlexNet showed that misclassification was found between C. *megacephala* and C. (*Achoetandrus*) rufifacies as well as between C. *megacephala* and L. *cuprina*. No misclassification was found for M. domestica. In addition, we created a web-application platform called thefly.ai to help users identify species of fly maggots in their own images using our classification model. The results from this study can be applied to identify further species by using other types of images. This model can also be used in the development of identification features in mobile applications. This study is a crucial step for integrating information from biology and AI-technology to develop a novel platform for use in forensic investigation.

## Material And Methods
### Preparation of Posterior spiracle
Slides of the posterior spiracle were prepared following the method of Bunchu et al. [13]. Briefly, the morphology of the posterior spiracle was investigated by using the hydroxide clearing method. Maggots of each species (*C. megacephala, C. (A.) rufifacies* (Diptera: Calliphoridae), *L. cuprina, and M. domestica*) were laboratory strains, which were obtained from the Medical Entomology Laboratory, Department of Microbiology and Parasitology, Faculty of Medical Science, Naresuan University. The posterior spiracles of each species were photographed under the light microscope connected to the digital camera. All the images were used in the training process. The identification of all specimens was confirmed by the experts. For demonstration purposes, example images of each species were inverted using the rgb colors from rgb (255, 255, 255) to rgb (0, 0, 0) by using the image adjustment function of Adobe photoshop 2021 to increase the clarity of the images.
### Image data set
In this study, the images of the posterior spiracles of four forensically-important fly species as mentioned above were analyzed. All original images have been categorized as “verified” after they were identified and confirmed by an expert. In total, 17,144 original images were used in this study and divided into training (12,000 images), validation (3,428), and testing (1,714) groups with a number ratio of 70:20:10, respectively. In the first step, we developed a custom object detection model for detection of position of posterior spiracle in the image by using Labellmg program. Five hundred images were used for training the object detection model. The custom object detection data set was encoded to the JSON format. After that, this custom data set was implied with the YOLO object detection algorithm to crop images tightly to each species. Cropped images less than 224x224 pixels were discarded from this study. This custom object detection model provided the confidence and accuracy ≥ 80%. The process of image detection was shown in Figure 1. The image data set was encoded to the JPEG format for the next model training.
### Model training
In this study, we compared the performance of four widely used models that vary in complexity of architecture to evaluate tradeoffs in accuracy and speed for species classification including ResNet-101, Densenet161, Vgg19_bn, and AlexNet. In the first step, we used the model from the previous step as mentioned above to speed up the training process. After randomly shuffling images in each species, the images within the species were divided by 70:20:10 ratio into training, validation, and testing groups. For each model, cropped images were resampled to the standard size for the input model. After using these models initially, we used 224x224 pixel images for Resnet-101, Densenet161, Vgg19_bn, and AlexNet. We used an image augmentation strategy following the previous study by Spiesman et al. [14]. Stochastic gradient descent (SGD) optimizer with an initial learning rate of 0.01 for all models were used. We used batch normalization and models were trained for the 50 epochs using Nvidia K80, T4, P4 and P100 GPUs. At the species level, two metric model performance was calculated, including precision and recall. Macro precision or mean of species-level precision scores and macro-recall or mean of species-level recall scores for each model were determined. The mean time needed to predict the image in the test data set was also quantified as the model speed. All speed tests run on the same system using Nvidia K80s, T4s, P4s and P100s GPUs. The best performance model from this study was selected and used to develop web applications for automatic species identification.

## Figures
|    |   |
| ------------ | ------------ |
|  ![Figure 1](https://assets.researchsquare.com/files/rs-1134033/v1/8c89c38064c03f20dfdb7d46.png?maxDims=1200x1200 "Figure 1") Figure 1. The processes of the custom object detection model used in this study |  ![Figure 1](https://assets.researchsquare.com/files/rs-1134033/v1/180a68b2de59991b96708224.png?maxDims=1200x1200 "Figure 2")Figure 2. Morphology of posterior spiracles of four different fly species after inverting the image colors; A: *Chrysomya (Achoetandrus) ruffifacies*, B: *Chrysomya megacephala*, C: *Lucilia cuprina*, D: *Musca domestica*  |
|   ![Figure 1](https://assets.researchsquare.com/files/rs-1134033/v1/573dbdfa60792679052c0758.png?maxDims=1200x1200 "Figure 3")Figure 3. Validation accuracy of the four different models during the training  |![Figure 1](https://assets.researchsquare.com/files/rs-1134033/v1/fafd64c54a95402fe8096dc3.png?maxDims=1200x1200 "Figure 4")Figure 4. tSNE visualization of the AlexNet model by dimensionality reduction of the penultimate features (The test data are shown in colors for different classes.)   |
| ![Figure 1](https://assets.researchsquare.com/files/rs-1134033/v1/828e88cd2029408b65387e7b.png?maxDims=1200x1200 "Figure 5") Figure 5. Visualization of hidden convolutional layers in AlexNet for four example images (To clearly show the patterns, we generated the color images; A: *Chrysomya (Achoetandrus) ruffifacies*, B: *Chrysomya megacephala*, C: *Lucilia cuprina*, D: *Musca domestica*)  | ![Figure 1](https://assets.researchsquare.com/files/rs-1134033/v1/37b1724c12156949ee7b898d.jpeg?maxDims=1200x1200 "Figure 6") Figure 6. The confusion matrix achieved by the AlexNet model (A) Validation (B) Test dataset.  |
|  ![Figure 1](https://assets.researchsquare.com/files/rs-1134033/v1/9d8d73c9c1e88d4ca7865e2b.png?maxDims=1200x1200 "Figure 7") Figure 7. Heatmap of attention maps of Alexnet on example images showing prediction accuracy (98.70-100%) of this model for classification of each fly species in different image conditions | ![Figure 1](https://assets.researchsquare.com/files/rs-1134033/v1/6e96bb6b8c12ab4c8a9db74e.png?maxDims=1200x1200 "Figure 8") Figure 8. Framework of the proposed interpretation architecture for deep learning models, Alexnet in this study |

## Declarations
### Acknowledgments
We are grateful for the financial support from the Naresuan University research fund (R2563C008 to Darlin Apasrawirote and Nophawan Bunchu). Ketsarin Thipphet and Pluemkamon Phuwanatsarunya are acknowledged for their assistance in rearing and maintaining fly colonies in the laboratory.
### Author contributions
D.A. conceived the study, contributed model training, and provided acquisition of funding. P.B. performed the modeling, designed all visualization, and created a web application (thefly.ai)., P.M. provided the critical feedback, editing, and approval of the final draft., W.N. prepared slides of posterior spiracles, and took photographs under a stereomicroscope, N.B. initiated and designed the study, identified the specimens, prepared the data sets, performed training of models, wrote the first draft of the manuscript. All authors reviewed the manuscript. 
### Data availability
The dataset and source codes for this study are publicly available through the second author’s GitHub repository: https://github.com/pharinyab/Fly-PosteriorSpiracles-AlexNet

## References

1. Bunchu, N. Blow fly (Diptera: Calliphoridae) in Thailand: distribution, morphological identification and medical importance appraisals. *Int. J. Parasitol.* Res. 4, 57–64 (2012).
2. Sukontason, K., et al. Forensic entomology cases in Thailand: a review of cases from 2000 to 2006. Parasitol. Res. 101, 1417–1423 (2007).
3. Harvey, M. L., Gasz, N. E. & Voss, S. C. Entomology-based methods for estimation of postmortem interval. Res. Rep. Forensic Med. Sci. 6, 1–9 (2016).
4. Boukaye, B. T., Bernard, K. F. & Fana, T. Deep convolution neural network for image recognition. Ecol. Inform. 48, 257–268 (2018).
5. Hernández-Serna, A. & Jiménez-Segura, L. F. Automatic identification of species with neural networks. PeerJ. 2, e563; 10.7717/peerj.563 (2014).
6. Motta, D., et al. Application of convolutional neural networks for classification of adult mosquitoes in the field. PLoS One. 14, e0210829 (2019).
7. Ong, S. Q., et al. Implementation of a deep learning model for automated classification of Aedes aegypti (Linnaeus) and Aedes albopictus (Skuse) in real time. Sci. Rep. 11, 9908 (2021).
8. Park, J., et al. Classification and morphological analysis of vector mosquitoes using deep convolutional neural networks. Sci. Rep. 10, 1012 (2020).
9. Ye, S., Lu, S., Bai, X. & Gu, J. ResNet-Locust-BN Network-Based Automatic Identification of East Asian Migratory Locust Species and Instars from RGB Images. Insects. 11, 458; 10.3390/insects11080458 (2020).
10. Amendt, J., et al. Forensic entomology in Germany. Forensic Sci Int. 113, 309–314 (2000).
11. Badenhorst, R. & Villet, M. H. The uses of *Chrysomya megacephala* (Fabricius, 1794) (Diptera: Calliphoridae) in forensic entomology. Forensic Sci. Res. 3, 2–15 (2018).
12. Catts, E. P. & Goff, M. L. Forensic entomology in criminal investigations. Annu. Rev. Entomol. 37, 253–272 (1992).
13. Bunchu, N., et al. Morphology and Developmental Rate of the Blow Fly, Hemipyrellia ligurriens (Diptera: Calliphoridae): Forensic Entomology Applications. J. Parasitol. Res. 2012, 371243. https://doi.org/10.1155/2012/371243 (2012).
14. Spiesman, B. J., et al. Assessing the potential for deep learning and computer vision to identify bumble bee species from images. Sci. Rep. 11, 7580 (2021).
15. Sukontason, K. L., et al. Larval morphology of *Chrysomya megacephala* (Fabricius) (Diptera: Calliphoridae) using scanning electron microscopy. J. Vector Ecol. 28, 47–52 (2003).
16. Sukontason, K., Piangjai, S., Siriwattanarungsee, S. & Sukontason, K. L. Morphology and developmental rate of blowflies *Chrysomya megacephala* and *Chrysomya rufifacies* in Thailand: Application in forensic entomology. Parasitol. Res. 102, 1207–1216 (2008).
17. Ozbulak, U. Convolutional Neural Network Visualizations. https://github.com/utkuozbulak/pytorch-cnn-visualizations (2019).
18. Acevedo, A., et al. Recognition of peripheral blood cell images using convolutional neural networks. Comput Methods Programs Biomed. 180, 105020 (2019).
19. Tan, C., et al. Identification of different species of *Zanthoxyli Pericarpium* based on convolution neural network. PLoS One. 15, e0230287 (2020).
20. Høye, T. T., et al. Deep learning and computer vision will transform entomology. Proc. Natl. Acad. Sci. USA. 118, e2002545117 (2021).
